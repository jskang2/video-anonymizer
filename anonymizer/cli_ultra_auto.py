#!/usr/bin/env python3
"""
Ultra ê³ ì„±ëŠ¥ íŒŒì´í”„ë¼ì¸ + ìë™ ìµœì í™” CLI
ê¸°ì¡´ ê²€ì¦ëœ ê³ ì„±ëŠ¥ íŒŒì´í”„ë¼ì¸ì— í•˜ë“œì›¨ì–´ ìë™ ê°ì§€ ë° ìµœì í™” ê¸°ëŠ¥ ì¶”ê°€
"""
import argparse
import sys
from pathlib import Path
from .config import Config
from .pipeline_ultra_optimized import UltraOptimizedPipeline
from .pipeline_speed_optimized import SpeedOptimizedPipeline
from .pipeline_auto_optimized import AutoOptimizedPipeline
from .auto_optimizer import AutoConfig, HardwareProfiler

def select_optimal_pipeline(hw_info, user_preference=None):
    """í•˜ë“œì›¨ì–´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì  íŒŒì´í”„ë¼ì¸ ìë™ ì„ íƒ"""
    
    if user_preference and user_preference != 'auto':
        return user_preference
    
    # GPU ë©”ëª¨ë¦¬ ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ ìë™ ì„ íƒ
    if not hw_info.gpu_available:
        print("[Auto] GPU ì—†ìŒ â†’ Auto íŒŒì´í”„ë¼ì¸ ì„ íƒ (CPU ìµœì í™”)")
        return 'auto'
    elif hw_info.gpu_memory_gb >= 8.0:
        print(f"[Auto] ê³ ì‚¬ì–‘ GPU ({hw_info.gpu_memory_gb:.1f}GB) â†’ Ultra íŒŒì´í”„ë¼ì¸ ì„ íƒ (ìµœê³  í’ˆì§ˆ)")
        return 'ultra'
    elif hw_info.gpu_memory_gb >= 4.0:
        print(f"[Auto] ì¤‘ì‚¬ì–‘ GPU ({hw_info.gpu_memory_gb:.1f}GB) â†’ Speed íŒŒì´í”„ë¼ì¸ ì„ íƒ (ì†ë„ ìš°ì„ )")
        return 'speed'
    else:
        print(f"[Auto] ì €ì‚¬ì–‘ GPU ({hw_info.gpu_memory_gb:.1f}GB ë¯¸ë§Œ) â†’ Auto íŒŒì´í”„ë¼ì¸ ì„ íƒ (ì•ˆì •ì„±)")
        return 'auto'

def main():
    parser = argparse.ArgumentParser(
        description="ğŸš€ Ultra ê³ ì„±ëŠ¥ ë¹„ë””ì˜¤ ìµëª…í™” + ìë™ ìµœì í™”",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ì™„ì „ ìë™ ìµœì í™” (ê¶Œì¥)
  python -m anonymizer.cli_ultra_auto --input video.mp4 --output result.mp4 --auto
  
  # íŠ¹ì • íŒŒì´í”„ë¼ì¸ ì§€ì • + ìë™ ì„¤ì •
  python -m anonymizer.cli_ultra_auto --input video.mp4 --output result.mp4 --pipeline ultra --auto
  
  # ìˆ˜ë™ ì„¤ì • (ê¸°ì¡´ ë°©ì‹)
  python -m anonymizer.cli_ultra_auto --input video.mp4 --output result.mp4 --pipeline ultra --batch-size 16
        """
    )
    
    # í•„ìˆ˜ ì¸ì
    parser.add_argument("--input", type=str, help="ì…ë ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--output", type=str, help="ì¶œë ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ")
    
    # ìë™ ìµœì í™” ì˜µì…˜
    parser.add_argument("--auto", action="store_true", 
                       help="ğŸ¤– í•˜ë“œì›¨ì–´ ìë™ ê°ì§€ ë° ìµœì  ì„¤ì • ì ìš© (ê¶Œì¥)")
    parser.add_argument("--hardware-info", action="store_true",
                       help="í•˜ë“œì›¨ì–´ ì •ë³´ë§Œ ì¶œë ¥í•˜ê³  ì¢…ë£Œ")
    
    # íŒŒì´í”„ë¼ì¸ ì„ íƒ
    parser.add_argument("--pipeline", type=str, 
                       choices=['auto', 'ultra', 'speed'], 
                       default='auto',
                       help="íŒŒì´í”„ë¼ì¸ ìœ í˜• (auto: ìë™ ì„ íƒ, ultra: ê³ í’ˆì§ˆ, speed: ê³ ì†ë„)")
    
    # ì„¤ì • íŒŒì¼
    parser.add_argument("--config", type=str, default="configs/gpu_optimized.yaml",
                       help="ê¸°ë³¸ ì„¤ì • íŒŒì¼")
    
    # ê³ ê¸‰ ì˜µì…˜ (ìë™ ì„¤ì • ì˜¤ë²„ë¼ì´ë“œìš©)
    parser.add_argument("--batch-size", type=int, help="GPU ë°°ì¹˜ í¬ê¸° (ìë™ ì„¤ì • ë¬´ì‹œ)")
    parser.add_argument("--device", type=str, help="CUDA ë””ë°”ì´ìŠ¤")
    parser.add_argument("--confidence", type=float, help="ê°ì²´ ê²€ì¶œ ì‹ ë¢°ë„ ì„ê³„ê°’")
    parser.add_argument("--safety-margin", type=int, help="ROI ì•ˆì „ ì—¬ë°± (í”½ì…€)")
    parser.add_argument("--force-cpu", action="store_true", help="GPU ì‚¬ìš©í•˜ì§€ ì•Šê³  CPUë§Œ ì‚¬ìš©")
    
    # ì„±ëŠ¥ ì˜µì…˜
    parser.add_argument("--max-performance", action="store_true",
                       help="ğŸš€ ìµœëŒ€ ì„±ëŠ¥ ëª¨ë“œ (ì‹œìŠ¤í…œ ìì› ìµœëŒ€ í™œìš©)")
    parser.add_argument("--balanced", action="store_true",
                       help="âš–ï¸ ê· í˜• ëª¨ë“œ (ì•ˆì •ì„±ê³¼ ì„±ëŠ¥ ê· í˜•)")
    
    args = parser.parse_args()
    
    # í•˜ë“œì›¨ì–´ ì •ë³´ê°€ ì•„ë‹Œ ê²½ìš° input/output í•„ìˆ˜ í™•ì¸
    if not args.hardware_info and (not args.input or not args.output):
        parser.error("--input and --output are required unless using --hardware-info")
    
    # í•˜ë“œì›¨ì–´ ì •ë³´ë§Œ ì¶œë ¥í•˜ëŠ” ê²½ìš°
    if args.hardware_info:
        print("ğŸ” í•˜ë“œì›¨ì–´ ì •ë³´ ê°ì§€ ì¤‘...")
        hw_info = HardwareProfiler.detect_hardware()
        
        print("\n" + "="*60)
        print("ğŸ’» ê°ì§€ëœ í•˜ë“œì›¨ì–´ ì •ë³´")
        print("="*60)
        print(f"ğŸ–¥ï¸  CPU: {hw_info.cpu_cores}ì½”ì–´ / {hw_info.cpu_threads}ìŠ¤ë ˆë“œ")
        print(f"ğŸ§  RAM: {hw_info.total_ram_gb:.1f}GB (ì‚¬ìš©ê°€ëŠ¥: {hw_info.available_ram_gb:.1f}GB)")
        
        if hw_info.gpu_available:
            print(f"ğŸ® GPU: {hw_info.gpu_name}")
            print(f"   â””â”€ ë©”ëª¨ë¦¬: {hw_info.gpu_memory_gb:.1f}GB")
            print(f"   â””â”€ Compute Capability: {hw_info.gpu_compute_capability[0]}.{hw_info.gpu_compute_capability[1]}")
        else:
            print("ğŸ® GPU: ê°ì§€ë˜ì§€ ì•ŠìŒ")
        
        # ê¶Œì¥ íŒŒì´í”„ë¼ì¸ ì¶œë ¥
        optimal_pipeline = select_optimal_pipeline(hw_info)
        print(f"\nğŸ’¡ ê¶Œì¥ íŒŒì´í”„ë¼ì¸: {optimal_pipeline}")
        return 0
    
    # ìë™ ìµœì í™” ëª¨ë“œ
    if args.auto or args.pipeline == 'auto':
        print("ğŸ¤– ìë™ ìµœì í™” ëª¨ë“œ í™œì„±í™”")
        print("ğŸ” í•˜ë“œì›¨ì–´ ë¶„ì„ ë° ìµœì  ì„¤ì • ìƒì„± ì¤‘...")
        
        # ìë™ ì„¤ì • ìƒì„±
        auto_config = AutoConfig()
        user_overrides = {}
        
        # ì„±ëŠ¥ ëª¨ë“œì— ë”°ë¥¸ ì˜¤ë²„ë¼ì´ë“œ
        if args.max_performance:
            print("ğŸš€ ìµœëŒ€ ì„±ëŠ¥ ëª¨ë“œ í™œì„±í™”")
            user_overrides.update({
                'confidence': 0.4,  # ë†’ì€ ì„ê³„ê°’ìœ¼ë¡œ ë¹ ë¥¸ ì²˜ë¦¬
                'batch_size_multiplier': 1.5,  # ë°°ì¹˜ í¬ê¸° 50% ì¦ê°€
                'cpu_workers_multiplier': 1.2,  # CPU ì›Œì»¤ 20% ì¦ê°€
            })
        elif args.balanced:
            print("âš–ï¸ ê· í˜• ëª¨ë“œ í™œì„±í™”")
            user_overrides.update({
                'confidence': 0.3,  # ì¤‘ê°„ ì„ê³„ê°’
                'batch_size_multiplier': 1.0,  # ê¸°ë³¸ ë°°ì¹˜ í¬ê¸°
                'cpu_workers_multiplier': 1.0,  # ê¸°ë³¸ CPU ì›Œì»¤
            })
        
        # ê°•ì œ CPU ëª¨ë“œ
        if args.force_cpu:
            user_overrides['gpu_available'] = False
            print("ğŸ–¥ï¸ ê°•ì œ CPU ëª¨ë“œ í™œì„±í™”")
        
        # ì‚¬ìš©ì ìˆ˜ë™ ì˜¤ë²„ë¼ì´ë“œ ì ìš©
        if args.batch_size:
            user_overrides['batch_size'] = args.batch_size
        if args.confidence:
            user_overrides['confidence'] = args.confidence
        if args.safety_margin:
            user_overrides['safety_margin_px'] = args.safety_margin
        if args.device:
            user_overrides['device'] = args.device
        
        optimal_settings = auto_config.generate_optimal_config(user_overrides)
        hw_info = auto_config.hardware_info
        
        # ìµœì  íŒŒì´í”„ë¼ì¸ ìë™ ì„ íƒ
        if args.pipeline == 'auto':
            selected_pipeline = select_optimal_pipeline(hw_info)
        else:
            selected_pipeline = args.pipeline
            print(f"[Auto] ì‚¬ìš©ì ì§€ì • íŒŒì´í”„ë¼ì¸: {selected_pipeline}")
        
        # Config ê°ì²´ ìƒì„± (ìë™ ìµœì í™” ì„¤ì • ì ìš©)
        config_overrides = {
            "input": args.input,
            "output": args.output,
            "device": "cuda:0",  # GPU í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ë¯€ë¡œ ê³ ì •
            "batch_size": optimal_settings.batch_size,
            "confidence": optimal_settings.confidence,
            "pose_model": optimal_settings.pose_model,
            "half_precision": optimal_settings.half_precision,
            "safety_margin_px": args.safety_margin or 12,
        }
        
    else:
        print("ğŸ”§ ìˆ˜ë™ ì„¤ì • ëª¨ë“œ")
        # ê¸°ì¡´ ìˆ˜ë™ ì„¤ì • ë°©ì‹
        config_overrides = {
            "input": args.input,
            "output": args.output,
            "pose_model": "yolov8s-pose.pt",
            "half_precision": False
        }
        
        # ì‚¬ìš©ì ì§€ì • ê°’ë“¤ ì ìš©
        if args.device is not None:
            # ë””ë°”ì´ìŠ¤ ë¬¸ìì—´ ì •ê·œí™” (ìˆ˜ì •ëœ detectors.pyì™€ í˜¸í™˜)
            if args.device.isdigit():
                config_overrides["device"] = f"cuda:{args.device}"
            else:
                config_overrides["device"] = args.device
        if args.batch_size is not None:
            config_overrides["batch_size"] = args.batch_size
        if args.confidence is not None:
            config_overrides["confidence"] = args.confidence
        if args.safety_margin is not None:
            config_overrides["safety_margin_px"] = args.safety_margin
        
        selected_pipeline = args.pipeline if args.pipeline != 'auto' else 'auto'
        hw_info = HardwareProfiler.detect_hardware()
    
    # Config ê°ì²´ ìƒì„±
    config_path = args.config if Path(args.config).exists() else None
    cfg = Config.from_yaml(config_path, config_overrides)
    
    # GPU ì •ë³´ ì¶œë ¥
    try:
        import torch
        gpu_available = torch.cuda.is_available()
    except ImportError:
        gpu_available = False
    
    if gpu_available and not args.force_cpu:
        device_id = 0
        if hasattr(cfg, 'device') and cfg.device.startswith('cuda:'):
            device_id = int(cfg.device.split(':')[1])
        print(f"[GPU] Device: {torch.cuda.get_device_name(device_id)}")
        print(f"[GPU] Memory: {torch.cuda.get_device_properties(device_id).total_memory / 1024**3:.1f} GB")
    else:
        print("[CPU] Using CPU-only mode")
    
    print(f"\nğŸš€ ì‹¤í–‰ ì„¤ì •:")
    print(f"   ğŸ“ ì…ë ¥: {cfg.input}")
    print(f"   ğŸ“ ì¶œë ¥: {cfg.output}")
    print(f"   ğŸ”§ íŒŒì´í”„ë¼ì¸: {selected_pipeline}")
    print(f"   ğŸ›ï¸  ë°°ì¹˜ í¬ê¸°: {cfg.batch_size}")
    print(f"   ğŸ¤– ëª¨ë¸: {cfg.pose_model}")
    print(f"   ğŸ¯ ì‹ ë¢°ë„: {cfg.confidence}")
    print(f"   ğŸ›¡ï¸ ì•ˆì „ ì—¬ë°±: {cfg.safety_margin_px}px")
    if hasattr(cfg, 'half_precision'):
        print(f"   âš¡ Half precision: {cfg.half_precision}")
    print("="*60)

    # íŒŒì´í”„ë¼ì¸ ì„ íƒ ë° ì‹¤í–‰
    try:
        if selected_pipeline == 'ultra':
            pipe = UltraOptimizedPipeline(cfg)
        elif selected_pipeline == 'speed':
            pipe = SpeedOptimizedPipeline(cfg)
        elif selected_pipeline == 'auto':
            pipe = AutoOptimizedPipeline(cfg)
        else:
            raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì´í”„ë¼ì¸: {selected_pipeline}")
        
        print(f"ğŸ¬ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹œì‘...")
        pipe.run(cfg.input, cfg.output)
        
        print(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {cfg.output}")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 1

    return 0

if __name__ == "__main__":
    sys.exit(main())