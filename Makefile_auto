# 자동 최적화 Makefile
# 하드웨어에 맞는 최적 설정을 자동으로 찾아 실행

# 기본 설정
IN ?= data/20140413.mp4
OUT ?= output/auto_optimized_result.mp4
STYLE ?= mosaic
SAFETY_MARGIN ?= 12

# Docker 이미지 이름
IMAGE_NAME = video-anonymizer-auto:latest

# 도움말
.PHONY: help
help:
	@echo "🚀 자동 최적화 비디오 익명화 Makefile"
	@echo ""
	@echo "주요 명령어:"
	@echo "  make auto-run         - 자동 최적화 실행 (하드웨어 맞춤 설정)"
	@echo "  make hardware-info    - 하드웨어 정보 확인"
	@echo "  make auto-docker      - Docker로 자동 최적화 실행"
	@echo "  make benchmark        - 성능 벤치마크 실행"
	@echo ""
	@echo "설정 옵션:"
	@echo "  IN=파일명            - 입력 비디오 (기본: $(IN))"
	@echo "  OUT=파일명           - 출력 비디오 (기본: $(OUT))"
	@echo "  STYLE=스타일         - 익명화 스타일 (기본: $(STYLE))"
	@echo "  SAFETY_MARGIN=숫자   - 안전 여백 (기본: $(SAFETY_MARGIN))"
	@echo ""
	@echo "고급 옵션:"
	@echo "  OVERRIDE='key=value' - 설정 오버라이드"
	@echo "  FORCE_CPU=1         - CPU만 사용"
	@echo ""
	@echo "예시:"
	@echo "  make auto-run IN=my_video.mp4 OUT=result.mp4"
	@echo "  make auto-run OVERRIDE='batch_size=16 confidence=0.25'"
	@echo "  make auto-run FORCE_CPU=1"

# 의존성 설치
.PHONY: install-auto
install-auto:
	@echo "📦 자동 최적화 의존성 설치 중..."
	pip install -r requirements_auto.txt
	@echo "✅ 설치 완료"

# 하드웨어 정보 확인
.PHONY: hardware-info
hardware-info:
	@echo "🔍 하드웨어 정보 감지 중..."
	python -m anonymizer.cli_auto --hardware-info

# 자동 최적화 실행 (로컬)
.PHONY: auto-run
auto-run:
	@echo "🚀 자동 최적화 파이프라인 실행 중..."
	@echo "입력: $(IN) → 출력: $(OUT)"
	@mkdir -p $(dir $(OUT))
ifdef OVERRIDE
	python -m anonymizer.cli_auto \
		--input "$(IN)" \
		--output "$(OUT)" \
		--style "$(STYLE)" \
		--safety-margin $(SAFETY_MARGIN) \
		$(foreach override,$(shell echo "$(OVERRIDE)" | tr ' ' '\n'),--override $(override)) \
		$(if $(FORCE_CPU),--force-cpu) \
		--verbose
else
	python -m anonymizer.cli_auto \
		--input "$(IN)" \
		--output "$(OUT)" \
		--style "$(STYLE)" \
		--safety-margin $(SAFETY_MARGIN) \
		$(if $(FORCE_CPU),--force-cpu) \
		--verbose
endif
	@echo "✅ 처리 완료: $(OUT)"

# 빠른 실행 (기본 설정)
.PHONY: quick-auto
quick-auto:
	@echo "⚡ 빠른 자동 최적화 실행"
	python -m anonymizer.cli_auto --input "$(IN)" --output "$(OUT)"

# Docker 이미지 빌드 (자동 최적화 포함)
.PHONY: build-auto
build-auto:
	@echo "🏗️ 자동 최적화 Docker 이미지 빌드 중..."
	docker build -f Dockerfile.auto -t $(IMAGE_NAME) .
	@echo "✅ Docker 이미지 빌드 완료: $(IMAGE_NAME)"

# Docker로 자동 최적화 실행
.PHONY: auto-docker
auto-docker:
	@echo "🐳 Docker 자동 최적화 실행 중..."
	@mkdir -p $(dir $(OUT))
	docker run --rm --gpus all \
		-v "$(PWD)":/workspace \
		-w /workspace \
		$(IMAGE_NAME) \
		python -m anonymizer.cli_auto \
		--input "$(IN)" \
		--output "$(OUT)" \
		--style "$(STYLE)" \
		--safety-margin $(SAFETY_MARGIN) \
		$(if $(OVERRIDE),$(foreach override,$(shell echo "$(OVERRIDE)" | tr ' ' '\n'),--override $(override))) \
		$(if $(FORCE_CPU),--force-cpu) \
		--verbose
	@echo "✅ Docker 처리 완료: $(OUT)"

# 성능 벤치마크
.PHONY: benchmark
benchmark:
	@echo "🏃‍♂️ 성능 벤치마크 실행 중..."
	python -m anonymizer.cli_auto --benchmark --input "$(IN)"

# 설정 캐시 삭제
.PHONY: clear-cache
clear-cache:
	@echo "🗑️ 설정 캐시 삭제 중..."
	rm -f auto_config_cache.json
	@echo "✅ 캐시 삭제 완료"

# 테스트 실행
.PHONY: test-auto
test-auto:
	@echo "🧪 자동 최적화 테스트 실행 중..."
	python -c "from anonymizer.auto_optimizer import HardwareProfiler, AutoConfig; print('✅ 자동 최적화 모듈 테스트 성공')"

# 상세 하드웨어 분석
.PHONY: analyze-hardware
analyze-hardware:
	@echo "🔬 상세 하드웨어 분석 중..."
	python -c "
from anonymizer.auto_optimizer import HardwareProfiler, AutoConfig
import torch

hw = HardwareProfiler.detect_hardware()
print(f'CPU 성능: {hw.cpu_cores}코어 / {hw.cpu_threads}스레드')
print(f'메모리: {hw.total_ram_gb:.1f}GB 총 / {hw.available_ram_gb:.1f}GB 사용가능')

if hw.gpu_available:
    print(f'GPU: {hw.gpu_name}')
    print(f'GPU 메모리: {hw.gpu_memory_gb:.1f}GB')
    print(f'CUDA 지원: {torch.cuda.is_available()}')
    if torch.cuda.is_available():
        print(f'CUDA 버전: {torch.version.cuda}')
        print(f'GPU 개수: {torch.cuda.device_count()}')
else:
    print('GPU: 감지되지 않음')

auto_config = AutoConfig()
settings = auto_config.generate_optimal_config()
"

# 모든 파이프라인 비교 테스트
.PHONY: compare-all
compare-all:
	@echo "📊 모든 파이프라인 성능 비교 중..."
	@echo "1. 기본 파이프라인"
	@time make run IN="$(IN)" OUT="output/basic_result.mp4" 2>&1 | grep "FPS\|시간"
	@echo ""
	@echo "2. Ultra 최적화 파이프라인"
	@time make run-ultra IN="$(IN)" OUT="output/ultra_result.mp4" 2>&1 | grep "FPS\|시간"
	@echo ""
	@echo "3. Speed 최적화 파이프라인"  
	@time make run-speed IN="$(IN)" OUT="output/speed_result.mp4" 2>&1 | grep "FPS\|시간"
	@echo ""
	@echo "4. 자동 최적화 파이프라인"
	@time make auto-run IN="$(IN)" OUT="output/auto_result.mp4" 2>&1 | grep "FPS\|시간"
	@echo ""
	@echo "📁 모든 결과 파일이 output/ 디렉토리에 저장되었습니다"

# 리소스 모니터링과 함께 실행
.PHONY: auto-run-monitor
auto-run-monitor:
	@echo "📊 리소스 모니터링과 함께 자동 최적화 실행"
	bash -c "
	(while true; do 
		echo -n '$(shell date +%T) - '; 
		nvidia-smi --query-gpu=utilization.gpu,utilization.memory,memory.used,memory.total --format=csv,noheader,nounits 2>/dev/null || echo 'GPU 정보 없음'; 
		sleep 2; 
	done) &
	MONITOR_PID=\$$!;
	trap 'kill \$$MONITOR_PID 2>/dev/null' EXIT;
	$(MAKE) auto-run IN='$(IN)' OUT='$(OUT)' $(if $(OVERRIDE),OVERRIDE='$(OVERRIDE)') $(if $(FORCE_CPU),FORCE_CPU=1)
	"

# 정리
.PHONY: clean-auto
clean-auto:
	@echo "🧹 자동 최적화 관련 파일 정리 중..."
	rm -f auto_config_cache.json
	rm -f output/auto_*.mp4
	@echo "✅ 정리 완료"