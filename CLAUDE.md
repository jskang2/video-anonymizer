# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Video Anonymizer MVP - A Docker-based video processing pipeline for automatic anonymization of specific body parts (eyes, elbows) using YOLO pose estimation and Haar cascade detection with OpenCV.

## Git ì›Œí¬í”Œë¡œìš°

### github í‘¸ì‰¬ë¥¼ ìœ„í•´ ë‹¤ìŒ ì •ë³´ ì‚¬ìš©:
GIT HUBì˜ Personal Access Token: [ë³´ì•ˆìƒ ì œê±°ë¨ - ë³„ë„ ê´€ë¦¬ í•„ìš”]

Github ì£¼ì†Œ : https://github.com/jskang2/video-anonymizer

### Git ì„¤ì • ë° í‘¸ì‹œ ê·œì¹™
.git ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ Git ì €ì¥ì†Œ ì´ˆê¸°í™” í• ê²ƒ (git init)
main ë¸Œëœì¹˜ ì‚¬ìš©í•  ê²ƒ
íŒŒì¼ ìƒì„± ë˜ëŠ” ìˆ˜ì •ì‹œ, íŒŒì¼ ìƒì„± ë˜ëŠ” ìˆ˜ì •í•œ í›„, git addì™€ commit ìˆ˜í–‰í•  ê²ƒ
íŒŒì¼ ì‚­ì œì‹œ git rm ë° commit ì‚¬ìš©í•  ê²ƒ

ì›ê²© ì €ì¥ì†Œì— í‘¸ì‹œí•  ë•Œ, ë¨¼ì € HTTP ë²„í¼ í¬ê¸°ë¥¼ ëŠ˜ë¦¬ê³  ì¡°ê¸ˆ ì”© ë‚˜ëˆ„ì–´ í‘¸ì‹œí•  ê²ƒ. ì—ëŸ¬ ì‹œ ì‘ì€ ë³€ê²½ì‚¬í•­ë§Œ í¬í•¨í•˜ëŠ” ìƒˆì»¤ë°‹ì„ ë§Œë“¤ì–´ í‘¸ì‹œí•  ê²ƒ


## Build & Development Commands

### ğŸš€ ìë™ ìµœì í™” ëª…ë ¹ì–´ (ê¶Œì¥)
```bash
# ì»¨í…Œì´ë„ˆ í™˜ê²½ ì„¤ì • (ìµœì´ˆ 1íšŒ)
make container-setup

# ğŸ¤– ì™„ì „ ìë™ ìµœì í™” (í•˜ë“œì›¨ì–´ ê°ì§€ + íŒŒì´í”„ë¼ì¸ ìë™ ì„ íƒ)
make run-auto IN=data/20140413.mp4

# ğŸ¤– ìë™ ìµœì í™” + ê³ í’ˆì§ˆ íŒŒì´í”„ë¼ì¸
make run-auto-ultra IN=data/20140413.mp4

# ğŸ¤– ìë™ ìµœì í™” + ìµœê³ ì†ë„ íŒŒì´í”„ë¼ì¸ (ê¶Œì¥)
make run-auto-speed IN=data/20140413.mp4

# í•˜ë“œì›¨ì–´ ì •ë³´ í™•ì¸
make hardware-info

# ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
make container-status

# ì»¨í…Œì´ë„ˆ ì •ë¦¬ (í•„ìš”ì‹œ)
make container-clean
```

### Docker Commands (ê¸°ë³¸)
```bash
# Build the container
make build
docker build -t video-anonymizer-mvp:latest .

# Download sample video for testing
make demo

# Run video processing (ê¸°ë³¸ íŒŒì´í”„ë¼ì¸)
make run IN=data/in.mp4 OUT=data/out.mp4 PARTS=eyes,elbows STYLE=mosaic

# Run tests
make test
docker run --rm -v $(PWD):/app video-anonymizer-mvp:latest pytest -q

# Direct CLI usage
docker run --rm -v $(PWD):/app video-anonymizer-mvp:latest \
  python -m anonymizer.cli --input data/in.mp4 --output data/out.mp4 \
  --parts eyes,elbows --style mosaic --safety 12 --ttl 5
```

### Local Development
```bash
# Install dependencies
pip install -r requirements.txt

# Run directly without Docker
python -m anonymizer.cli --config configs/default.yaml

# Run single test
pytest tests/test_smoke.py -v
pytest tests/test_smoke.py::test_smoke -v
```

## Core Architecture

### Processing Pipeline Flow
1. **VideoReader** â†’ frame-by-frame processing
2. **Detection Phase** â†’ parallel detection of eyes (Haar cascades) and elbows (YOLO pose keypoints)
3. **ROI Generation** â†’ convert detections to regions of interest with safety margins
4. **TTL Logic** â†’ maintain previous ROIs for specified frames when detection fails (reduces flicker)
5. **Mask Creation** â†’ soft masks with feathering for smooth blending
6. **Anonymization** â†’ apply style (mosaic/gaussian/boxblur/pixelate) to masked regions
7. **VideoWriter** â†’ output processed frames

### Key Components

**AnonymizePipeline** (`pipeline.py`) - Main orchestrator that coordinates the entire processing flow with TTL-based ROI persistence.

**Detection System** (`detectors.py`):
- `PoseDetector`: YOLOv8-pose wrapper for 17-point COCO keypoints, extracts elbow positions (indices 7,8)
- `FaceEyeDetector`: Haar cascade wrapper for face/eye detection with nested ROI processing

**ROI System** (`roi.py`):
- Converts keypoints to circular ROIs (elbows) and bounding boxes to elliptical ROIs (eyes)
- Implements adaptive sizing based on elbow-to-wrist distance
- Creates soft masks with Gaussian feathering for natural blending

**Configuration** (`config.py`): Dataclass-based config with YAML loading and CLI override support.

### Critical Architecture Details

**TTL Anti-Flicker Logic**: When detections fail, the pipeline reuses previous ROIs for `ttl_frames` to prevent flickering. This is essential for consistent anonymization across frames.

**ROI Coordinate System**: All ROIs use image pixel coordinates (float) with adaptive sizing:
- Elbows: Circle radius = 0.5 Ã— elbow-to-wrist distance (min 12px) + safety margin
- Eyes: Ellipse dimensions = bounding box dimensions + safety margin

**Processing Styles**:
- `mosaic/pixelate`: Downsample to 1/16 resolution then upscale with nearest interpolation
- `gaussian`: 25Ã—25 kernel Gaussian blur
- `boxblur`: 25Ã—25 box filter

**Memory Efficiency**: Frame-by-frame processing with immediate output writing, no batch loading.

## Configuration

Default configuration in `configs/default.yaml` with CLI override support. Key parameters:
- `safety_margin_px`: Expands ROI boundaries (default: 12px)
- `ttl_frames`: Frames to maintain ROI when detection fails (default: 5)
- `pose_model`: YOLOv8 variant (default: yolov8n-pose.pt)
- `style`: Anonymization method (mosaic|gaussian|boxblur|pixelate)

## Testing Strategy

**Smoke Test** (`tests/test_smoke.py`): Creates synthetic 10-frame black video, processes through full pipeline, verifies output file creation and non-zero size.

For development, use synthetic videos for consistent testing since real videos may have detection variance.

## Development Notes

**Model Dependencies**: YOLO models download automatically on first use. Eye/face cascades are included with OpenCV.

**Video I/O**: Uses OpenCV VideoCapture/VideoWriter with MP4V codec. FFmpeg included in Docker for broader format support.

**Error Handling**: Missing keypoints return `None`, empty detections trigger TTL fallback logic.

**Performance**: CPU-optimized with yolov8n-pose.pt (nano model). GPU version available via Dockerfile.gpu.

## ğŸ¤– ìë™ ìµœì í™” ì‹œìŠ¤í…œ (NEW)

### í•˜ë“œì›¨ì–´ ìë™ ê°ì§€ ë° ìµœì  ì„¤ì •
```bash
# í•˜ë“œì›¨ì–´ ì •ë³´ í™•ì¸
make hardware-info
```

**ê°ì§€ë˜ëŠ” í•˜ë“œì›¨ì–´ ì •ë³´:**
- CPU ì½”ì–´ ìˆ˜ ë° ìŠ¤ë ˆë“œ ìˆ˜
- GPU ëª¨ë¸ ë° ë©”ëª¨ë¦¬ í¬ê¸° 
- ì‹œìŠ¤í…œ RAM ìš©ëŸ‰
- GPU Compute Capability

**ìë™ ìµœì í™”ë˜ëŠ” ì„¤ì •ê°’:**
- `batch_size`: GPU ë©”ëª¨ë¦¬ ê¸°ë°˜ ìµœì  ë°°ì¹˜ í¬ê¸° (1-64)
- `cpu_workers`: CPU ì½”ì–´ ê¸°ë°˜ ìµœì  ì›Œì»¤ ìˆ˜
- `confidence`: GPU ì„±ëŠ¥ ê¸°ë°˜ ê²€ì¶œ ì„ê³„ê°’
- `pose_model`: GPU ë©”ëª¨ë¦¬ì— ë”°ë¥¸ ìµœì  ëª¨ë¸ ì„ íƒ
- `half_precision`: GPU ì§€ì› ì—¬ë¶€ì— ë”°ë¥¸ FP16 ì‚¬ìš©
- `eye_detection_interval`: GPU ì„±ëŠ¥ì— ë”°ë¥¸ ê²€ì¶œ ê°„ê²©

### ì„±ëŠ¥ ë¹„êµ

| ëª¨ë“œ | ë°°ì¹˜í¬ê¸° | CPU ì›Œì»¤ | GPU í™œìš© | ì²˜ë¦¬ì†ë„ |
|------|----------|----------|----------|----------|
| ê¸°ë³¸ | 8 | 16 | 30% | ~30 FPS |
| ìë™ìµœì í™” | 64 | 32 | 95% | ~95 FPS |

### Docker ì»¨í…Œì´ë„ˆ ìµœì í™”

**ë¬¸ì œì :**
- `--rm` í”Œë˜ê·¸ë¡œ ë§¤ë²ˆ ìƒˆ ì»¨í…Œì´ë„ˆ ìƒì„±
- YOLO ëª¨ë¸ ì¬ë‹¤ìš´ë¡œë“œ (300MB+)
- ì´ˆê¸°í™” ì‹œê°„ 30ì´ˆ+

**í•´ê²°ì±…: Named Container + Volume**
```bash
# ìµœì´ˆ ì„¤ì • (1íšŒ)
make container-setup

# ì´í›„ ë°”ë¡œ ì‚¬ìš©
make run-auto-speed IN=data/video.mp4
```

**ê°œì„  íš¨ê³¼:**
- ì‹œì‘ ì‹œê°„: 30ì´ˆ â†’ 3ì´ˆ
- ëª¨ë¸ ì¬ë‹¤ìš´ë¡œë“œ ì œê±°
- ì„¤ì • ìºì‹œ ìœ ì§€
- ì•ˆì •ì„± í–¥ìƒ

### ì„¤ì •ê°’ ê´€ë¦¬

**ìë™ ìºì‹œ ì‹œìŠ¤í…œ:**
- íŒŒì¼: `auto_config_cache.json`
- í•˜ë“œì›¨ì–´ ë³€ê²½ì‹œ ìë™ ì¬ê°ì§€
- ì‚¬ìš©ì ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥

```json
{
  "hardware_info": {
    "gpu_name": "NVIDIA GeForce RTX 3060 Ti",
    "gpu_memory_gb": 8.0,
    "cpu_cores": 16
  },
  "optimal_settings": {
    "batch_size": 64,
    "cpu_workers": 8,
    "confidence": 0.4
  }
}
```

**ì„¤ì • ìš°ì„ ìˆœìœ„:**
1. ëª…ë ¹í–‰ í”Œë˜ê·¸ (ìµœìš°ì„ )
2. ìºì‹œëœ ìë™ ì„¤ì •
3. ê¸°ë³¸ê°’

### íŒŒì´í”„ë¼ì¸ ì„ íƒ ê°€ì´ë“œ

| GPU ë©”ëª¨ë¦¬ | ê¶Œì¥ íŒŒì´í”„ë¼ì¸ | íŠ¹ì§• |
|------------|----------------|------|
| 8GB+ | `run-auto-ultra` | ìµœê³  í’ˆì§ˆ, ë°°ì¹˜í¬ê¸° 64 |
| 4GB+ | `run-auto-speed` | ìµœê³  ì†ë„, ë°°ì¹˜í¬ê¸° 32 |
| 4GB ë¯¸ë§Œ | `run-auto` | ì•ˆì •ì„± ìš°ì„ , ìë™ ì¡°ì • |
| GPU ì—†ìŒ | `run-auto` | CPU ìµœì í™” |