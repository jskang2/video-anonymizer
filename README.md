# 🤖 Video Anonymizer - AI Auto-Optimized (YOLO Pose + GPU + Auto Hardware Detection)

대량 영상에서 **팔꿈치/눈** 등 특정 부위를 자동 비식별화(모자이크/블러)하는 **AI 자동 최적화 버전**입니다. 

🤖 **새로운 AI 자동 최적화 시스템:**
- **하드웨어 자동 감지**: CPU, GPU, RAM 자동 분석
- **설정값 자동 최적화**: 배치크기, 워커수, 임계값 자동 검색
- **스마트 컨테이너**: 모델 재다운로드 없이 3초 내 시작
- **성능 최대화**: CPU/GPU 사용률 95%+ 달성

## 🤖 AI 자동 최적화 성능

### 성능 비교 (RTX 3060 Ti 기준)

| 모드 | 배치크기 | CPU 워커 | GPU 활용 | 처리속도 | 초기화 시간 |
|------|----------|----------|----------|----------|---------------|
| 기존 수동 | 8 | 16 | 30% | ~30 FPS | 30초+ |
| 🤖 자동최적화 | 64 | 32 | 95% | **93+ FPS** | **3초** |

### 최신 성능 결과
- **최고 속도**: **93.49 FPS** (자동 최적화 Speed 파이프라인)
- **고품질 속도**: **69+ FPS** (자동 최적화 Ultra 파이프라인)
- **자원 활용**: CPU 95% + GPU 95% 동시 활용
- **시작 속도**: 30초 → 3초 (10배 개선)
- **안정성**: 모델 다운로드 없이 즉시 시작

## 🚀 빠른 시작 - AI 자동 최적화 (권장)

### 1. Docker 이미지 빌드 (최초 1회)
```bash
make build
```

### 2. 스마트 컨테이너 환경 설정 (최초 1회)
```bash
make container-setup
```

### 3. 🤖 AI 자동 최적화 실행 (권장)

**옵션 1: 완전 자동 (최간단)**
```bash
# 하드웨어 감지 + 파이프라인 자동 선택 + 설정 자동 최적화
make run-auto IN=data/20140413.mp4
```

**옵션 2: 자동 + 최고속도 (권장)**
```bash
# 하드웨어 맞춤 설정 + 최고속도 파이프라인
make run-auto-speed IN=data/20140413.mp4
```

**옵션 3: 자동 + 최고품질**
```bash
# 하드웨어 맞춤 설정 + 최고품질 파이프라인
make run-auto-ultra IN=data/20140413.mp4
```

### 4. 하드웨어 정보 확인
```bash
make hardware-info
```

### 5. 기존 수동 최적화 (전문용)
```bash
# 수동 설정으로 품질 우선
make run-ultra IN=my_video.mp4 CONFIDENCE=0.25 SAFETY_MARGIN=15

# 수동 설정으로 속도 우선
make run-speed IN=my_video.mp4 BATCH_SIZE=64
```

## 🔧 실행 옵션 상세

`make` 명령어 실행 시 다음 파라미터를 지정할 수 있습니다.

- `IN`: 입력 영상 경로 (기본값: `data/20140413.mp4`)
- `OUT`: 출력 영상 경로 (파이프라인에 따라 자동 지정)
- `CONFIDENCE`: 탐지 민감도 (값이 낮을수록 더 많이 탐지, 기본값: `ultra`=0.3, `speed`=0.5)
- `SAFETY_MARGIN`: 마스킹 영역의 여백 (px 단위, 기본값: 12)
- `BATCH_SIZE`: GPU 배치 크기 (기본값: `ultra`=16, `speed`=32)

## 📈 파이프라인 비교 및 선택 가이드

### 🤖 AI 자동 최적화 (권장)

| 명령어 | 특징 | 처리속도 | GPU 메모리 | 사용 시점 |
|---------|------|----------|-------------|----------|
| `make run-auto` | 하드웨어 감지 + 전역 자동화 | 자동 최적 | 모든 GPU | 처음 사용자 (최간단) |
| `make run-auto-speed` | 자동 설정 + 최고속도 | **93+ FPS** | 4GB+ | 빠른 처리 (권장) |
| `make run-auto-ultra` | 자동 설정 + 최고품질 | **69+ FPS** | 8GB+ | 높은 정확도 |

### 수동 최적화 (전문용)

| 명령어 | 특징 | 처리속도 | 설정 요구 | 사용 시점 |
|---------|------|----------|-------------|----------|
| `make run-ultra` | 수동 품질 중심 | ~70 FPS | 파라미터 지식 | 정밀 설정 필요시 |
| `make run-speed` | 수동 속도 중심 | ~97 FPS | 성능 튜닝 | 매개변수 실험 |
| `make run` | 기본 CPU 처리 | ~5 FPS | GPU 없음 | 호환성 테스트 |

### 🏆 추천 사용법

1. **처음 사용자**: `make run-auto` (모든 것이 자동)
2. **속도 중심**: `make run-auto-speed` (93+ FPS 달성)
3. **품질 중심**: `make run-auto-ultra` (69+ FPS, 고품질)
4. **전문 사용자**: 수동 최적화 + 파라미터 튜닝

## 🤖 새로운 AI 자동 최적화 기능

### 하드웨어 자동 감진
```bash
make hardware-info
```
**감지 정보:**
- CPU: 코어/스레드 수 → 최적 워커 수 산출
- GPU: 모델명, 메모리, Compute Capability → 최적 배치크기 산출
- RAM: 전체/사용가능 용량 → 최적 큐 크기 산출

### 스마트 컨테이너 관리
```bash
# 최초 설정
make container-setup

# 상태 확인
make container-status

# 정리 (필요시)
make container-clean
```

**개선 효과:**
- 시작 시간: 30초 → 3초 (90% 단축)
- YOLO 모델 재다운로드 제거 (300MB+ 절약)
- 설정 캐시 유지 → 일관성 및 안정성 향상

### 자동 설정값 관리

**캐시 파일:** `auto_config_cache.json`
```json
{
  "hardware_info": {
    "gpu_name": "NVIDIA GeForce RTX 3060 Ti",
    "gpu_memory_gb": 8.0,
    "cpu_cores": 16
  },
  "optimal_settings": {
    "batch_size": 64,
    "cpu_workers": 8,
    "confidence": 0.4,
    "pose_model": "yolov8s-pose.pt"
  }
}
```

**설정 우선순위:**
1. 명령행 플래그 (e.g., `--batch-size 32`)
2. 캐시된 자동 설정
3. 안전한 기본값

## ⚠️ 주의사항 및 사용 팁

### 기술적 주의사항
- **눈 검출**: Haar 기반으로 조명/각도에 민감. AI가 자동으로 간격 조정
- **팔꿈치 검출**: YOLOv8-pose 키포인트 의존. AI가 모델 자동 선택
- **GPU 메모리**: OOM 발생시 AI가 배치크기 자동 감소

### 최적 사용법
1. **처음**: `make container-setup` 실행 (하드웨어 감지 및 모델 다운로드)
2. **일반**: `make run-auto-speed` 사용 (가장 빠른 속도)
3. **고품질**: `make run-auto-ultra` 사용 (최고 품질)
4. **문제시**: `make hardware-info`로 하드웨어 상태 확인

### 성능 모니터링
- CPU/GPU 사용률 95%+ 달성 시 최적 상태
- 처리 속도가 떨어지는 경우 AI가 자동 조정
- OOM 에러 발생 시 자동으로 배치크기 감소

## 🛠️ 개발자 정보

### Core Architecture

**AnonymizePipeline** (`pipeline.py`) - Main orchestrator that coordinates the entire processing flow with TTL-based ROI persistence.

**Detection System** (`detectors.py`):
- `PoseDetector`: YOLOv8-pose wrapper for 17-point COCO keypoints, extracts elbow positions (indices 7,8)
- `FaceEyeDetector`: Haar cascade wrapper for face/eye detection with nested ROI processing

**ROI System** (`roi.py`):
- Converts keypoints to circular ROIs (elbows) and bounding boxes to elliptical ROIs (eyes)
- Implements adaptive sizing based on elbow-to-wrist distance
- Creates soft masks with Gaussian feathering for natural blending

**Auto-Optimization System** (`auto_optimizer.py`):
- `HardwareProfiler`: Automatic hardware detection and analysis
- `AutoTuner`: Optimal settings calculation based on hardware capabilities
- `RuntimeOptimizer`: Dynamic performance monitoring and adjustment
- `AutoConfig`: Configuration generation and caching system

### Configuration

Default configuration in `configs/default.yaml` with CLI override support. Key parameters:
- `safety_margin_px`: Expands ROI boundaries (default: 12px)
- `ttl_frames`: Frames to maintain ROI when detection fails (default: 5)
- `pose_model`: YOLOv8 variant (default: yolov8n-pose.pt)
- `style`: Anonymization method (mosaic|gaussian|boxblur|pixelate)

### Testing Strategy

**Smoke Test** (`tests/test_smoke.py`): Creates synthetic 10-frame black video, processes through full pipeline, verifies output file creation and non-zero size.

For development, use synthetic videos for consistent testing since real videos may have detection variance.

### Development Notes

**Model Dependencies**: YOLO models download automatically on first use. Eye/face cascades are included with OpenCV.

**Video I/O**: Uses OpenCV VideoCapture/VideoWriter with MP4V codec. FFmpeg included in Docker for broader format support.

**Error Handling**: Missing keypoints return `None`, empty detections trigger TTL fallback logic.

**Performance**: Auto-optimized based on hardware capabilities. GPU version uses Dockerfile.gpu.